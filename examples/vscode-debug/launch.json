{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Debug",
      "type": "cppdbg",
      "request": "launch",
      "program": "${workspaceFolder}/build_debug/bin/llama-cli",
      "args": [
        "-m", "path/to/your/model.gguf",
        "-p", "Crafting an AI model can follow these steps:",
        "-c", "512", "-n", "128", "-t", "10"
      ],
      "stopAtEntry": false,
      "cwd": "${workspaceFolder}",
      "environment": [
        { "name": "LLAMA_ARG_CTX_SIZE", "value": "4096" }
      ],
      "externalConsole": false,
      "MIMode": "gdb",
      "setupCommands": [
        {
          "description": "Enable pretty-printing for gdb",
          "text": "-enable-pretty-printing",
          "ignoreFailures": true
        }
      ]
    }
  ]
}
